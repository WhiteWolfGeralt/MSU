{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Курс по машинному обучению,   ВМК МГУ\n",
    "## Градиентный бустинг деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важно! О формате сдачи\n",
    "\n",
    "* **Практически все выделенные задания из ноутбука оцениваются по системе <font color='red'>кросс-рецензирования</font>. Задания, в котором надо реализовать свой код и послать в систему, выделены здесь и в pdf отдельно**\n",
    "* **В этом ноутбуке есть задание на ML-решение**\n",
    "* **При решении ноутбука используйте данный шаблон. Не нужно удалять текстовые ячейки c разметкой частей ноутбука и формулировками заданий. Добавлять свои ячейки, при необходимости, конечно можно**\n",
    "* **Везде, где в формулровке задания есть какой-либо вопрос (или просьба вывода), необходимо прописать ответ в ячейку (код или markdown).**\n",
    "* **Наличие кода решения обязательно. Письменные ответы на вопросы без сопутствующего кода оцениваются в 0 баллов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**А также..**\n",
    "\n",
    "Если в ячейке написана фраза \"Вывод\"/\"Ответ на вопрос\" итд, то ожидается ответ в виде текста (можете добавить ячейки с кодом, если считаете это необходимым, но это необязательно). Если в ячейке написано \"Your code here\", то ожидается ответ в виде кода (можете добавить ячейки с кодом, если считаете это необходимым, но это необязательно). Если есть и ячейка с фразой \"Вывод\", и ячейка с фразой \"Your code here\", то в ответе ожидается и код, и текст)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__В этом задании вы..:__\n",
    "\n",
    "- Познакомитесь с несколькими новыми библиотеками машинного обучения\n",
    "- Сравните между собой разные реализации градиентных бустингов\n",
    "- Примените все полученные знания для получения лучшего скора на датасете фильмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Введение\n",
    "\n",
    "Привет, ребятушки!\n",
    "\n",
    "Сегодня мы с вами будем решать очень важную задачу, а именно оценивать цену поддержанных автомобилей в ряде стран. Делать мы это будем с помощью различных методов градиентного бустинга. Мы с вами узнаем, что в мире существует не только sklearn, и что существуют библиотеки, облегчающие нам задачу поиска оптимальных параметров для моделей.\n",
    "\n",
    "**Внимание! Во всех заданиях в качестве целевой метрики используется MAE (средняя абсолютная ошибка).** Значение MAE вычисляется как\n",
    "\n",
    "$$\n",
    "  MAE = \\sum_{i = 1}^N\\dfrac{|a(x_i) - y_i|}{N},\n",
    "$$\n",
    "\n",
    "где $N$ - число объектов в тестовой выборке, $x_i$ - вектор признаков i-го объекта, $a(x_i)$ - предсказание на i-ом объекте, $y_i$ - значение целевого признака на i-м объекте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Установка дополнительных библиотек.\n",
    "\n",
    "В этом задании нам понадобятся три бибиотеки, которыми вы ранее не пользовались в этом курсе, а именно:\n",
    "\n",
    "**XGBoost**: Документация [здесь](https://xgboost.readthedocs.io/en/stable/).<br />\n",
    "**LightGBM**: Документация [здесь](https://lightgbm.readthedocs.io/en/latest/index.html). Также дополнительно про установку [тут](https://pypi.org/project/lightgbm/).<br />\n",
    "**Catboost**: Документация [здесь](https://catboost.ai/en/docs/). Можно найти также некоторую информацию на русском [тут](https://habr.com/ru/company/otus/blog/527554/).<br />\n",
    "**HyperOpt**: Документация [здесь](http://hyperopt.github.io/hyperopt/). <br />\n",
    "\n",
    "Все библиотеки легко ставятся через pip (либо альтернативные установщики вроде conda).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Как правильно перебирать параметры\n",
    "\n",
    "В этом ноутбуке мы будем несколько раз заниматься поиском оптимальных параметров для градиентного бустинга, перебирая задания по заданной сетке. В этом задании от Вас не будет требоваться найти самые лучшие параметры, но всё равно важно правильно составлять сетку для перебора. Для этого нужно понимать суть параметров и их смысл.\n",
    "\n",
    "\n",
    "\n",
    "**learning_rate** -- темп обучения нашего метода. Для этого метода сетка перебора должна быть логарифмической, т.е. перебирать порядковые значения (к примеру, [1e-3, 1e-2, 1e-1, 1]). В большинстве случаев достаточно перебрать значения от 1e-5 до 1.<br />\n",
    "**max_depth** -- максимальная глубина деревьев в ансамбле. Вообще говоря, эта величина зависит от числа признаков, но обычно лучше растить небольшие деревья. К примеру, библиотека CatBoost, которую мы будем исследовать сегодня, рекомендует перебирать значения до 10 (и уточняется, что обычно оптимальная глубина лежит от 6 до 10).<br />\n",
    "**n_estimators** -- количество деревьев в ансамбле. Обычно стоит перебирать с каким-то крупным шагом (можно по логарифмической сетке). Здесь важно найти баланс между производительностью, временем обучения и качеством. Обычно нескольких тысяч деревьев бывает достаточно.<br />\n",
    "\n",
    "Учтите, что в реальных задачах необходимо следить за тем, что оптимальные значения параметров не попадают на границы интервалов, т.е. что вы нашли хотя бы локальный минимум. Если Вы перебрали значения параметра от 1 до 10 и оказалось, что 10 - оптимальное значение, значит следует перебрать и бОльшие числа, чтобы убедиться, что качество не улучшается дальше (или по крайней мере убедиться, что рост качества сильно замедляется и на сильное улучшения рассчитывать не стоит.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка датасета\n",
    "\n",
    "Все библиотеки, используемые сегодня, мы будем проверять на одних и тех же параметрах: n_estimators=1000, max_depth=5, learning_rate=0.1. Таким образом мы устанавливаем, соответственно, число деревьев в ансамбле равным 1000, ограничиваем максимальную глубину деревьев 5 и устанавливаем темп обучения равным 0.1. Создадим сразу словарь, чтобы передавать эти параметры создаваемым регрессорам (если вдруг не знали, словарь можно передавать как параметры, поставив перед ним **).\n",
    "\n",
    "Эти параметры мы вынесем в отдельную переменную `test_parameters`.\n",
    "\n",
    "<span style=\"color:red\">Загрузите датасет, с которым мы будем работать. Его можно найти на платформе cv-gml.ru, в задании `Град. бустинг (ML)`, по ссылке `Дополнительные файлы для решения`. Если Вы решите сохранить этот файл не рядом с ноутбуком, Вы можете исправить путь к этому файлу во второй ячейке ноутбука (в строке с `read_csv`).</span>\n",
    "\n",
    "При желании можно почитать про этот датасет на платформе kaggle: [ссылка на данные](https://www.kaggle.com/bushnag/cars-in-the-middle-east?select=dataframe_YesIndex_YesHeader_C.csv). <span style=\"color:red\"> Не скачивайте датасет из kaggle для выполнения ноутбука, поскольку его могут изменить.</span> Нас интересует файл dataframe_YesIndex_YesHeader_C.csv, поскольку он уже хорошо предобработан (хотя, конечно, датасаентисты должны сами уметь это делать, но ладно).\n",
    "Давайте попробуем загрузить датасет в память и посмотреть, как он выглядит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "from hyperopt import hp, tpe, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Engine Capacity</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Drive Type</th>\n",
       "      <th>Fuel Tank Capacity</th>\n",
       "      <th>Fuel Economy</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Top Speed</th>\n",
       "      <th>...</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Trunk Capacity</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>currency</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.245</td>\n",
       "      <td>1.670</td>\n",
       "      <td>1.515</td>\n",
       "      <td>2.550</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Mitsubishi Attrage 2021 1.2 GLX (Base)</td>\n",
       "      <td>34099.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.245</td>\n",
       "      <td>1.670</td>\n",
       "      <td>1.515</td>\n",
       "      <td>2.550</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Mitsubishi Attrage 2021 1.2 GLX (Base)</td>\n",
       "      <td>34099.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.864</td>\n",
       "      <td>1.716</td>\n",
       "      <td>1.721</td>\n",
       "      <td>2.513</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>Fiat Fiorino 2021 1.4L Standard</td>\n",
       "      <td>41250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.354</td>\n",
       "      <td>1.994</td>\n",
       "      <td>1.529</td>\n",
       "      <td>2.635</td>\n",
       "      <td>510.0</td>\n",
       "      <td>Renault Symbol 2021 1.6L PE</td>\n",
       "      <td>44930.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.314</td>\n",
       "      <td>1.809</td>\n",
       "      <td>1.624</td>\n",
       "      <td>2.585</td>\n",
       "      <td>448.0</td>\n",
       "      <td>MG ZS 2021 1.5L STD</td>\n",
       "      <td>57787.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Engine Capacity  Cylinders  Drive Type  Fuel Tank Capacity  Fuel Economy  \\\n",
       "0              1.2          3           0                42.0           4.9   \n",
       "1              1.2          3           0                42.0           4.9   \n",
       "2              1.4          4           0                45.0           6.3   \n",
       "3              1.6          4           0                50.0           6.4   \n",
       "4              1.5          4           0                48.0           5.8   \n",
       "\n",
       "   Fuel Type  Horsepower  Torque  Transmission  Top Speed  ...  Acceleration  \\\n",
       "0          0          76   100.0             0        170  ...          14.0   \n",
       "1          0          76   100.0             0        170  ...          14.0   \n",
       "2          0          75   118.0             1        156  ...          16.0   \n",
       "3          0         102   145.0             0        180  ...          11.0   \n",
       "4          0         112   150.0             0        170  ...          10.9   \n",
       "\n",
       "   Length  Width  Height  Wheelbase  Trunk Capacity  \\\n",
       "0   4.245  1.670   1.515      2.550           450.0   \n",
       "1   4.245  1.670   1.515      2.550           450.0   \n",
       "2   3.864  1.716   1.721      2.513          2800.0   \n",
       "3   4.354  1.994   1.529      2.635           510.0   \n",
       "4   4.314  1.809   1.624      2.585           448.0   \n",
       "\n",
       "                                     name    price  currency  Country  \n",
       "0  Mitsubishi Attrage 2021 1.2 GLX (Base)  34099.0         0        0  \n",
       "1  Mitsubishi Attrage 2021 1.2 GLX (Base)  34099.0         0        0  \n",
       "2         Fiat Fiorino 2021 1.4L Standard  41250.0         0        0  \n",
       "3             Renault Symbol 2021 1.6L PE  44930.0         0        0  \n",
       "4                     MG ZS 2021 1.5L STD  57787.0         0        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parameters = {\"n_estimators\": 1000, \"max_depth\": 5, \"learning_rate\":0.1}\n",
    "\n",
    "df = pd.read_csv('dataframe_YesIndex_YesHeader_C.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Задание 0 (без проверки, 0 баллов)\n",
    "\n",
    "Посмотрите на цены автомобилей. Попробуйте понять, написаны они в одной валюте или нет. Если нет -- будут ли у нас серьезные проблемы при использовании деревьев? Стоит ли нам что-то сделать для того, чтобы нивелировать эту проблему?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В глаза бросаются две проблемы: у нас имеется информация о производителе автомобиля, скрытая в текстовой переменной модели автомобиля (нет отдельного признака). Также имеются некоторые категориальные переменные. Со всем этим безобразием надо что-то сделать.\n",
    "\n",
    "### **Задание 1 (кросс-проверка, 3 балла)**\n",
    "**Данные**: датасет со стоимостью поддержанных автомобилей  \n",
    "**Цели**: В данном задании следует выполнить следующие пункты (выполнять можно в любом порядке)\n",
    "1. Изучить датасет, проверить наличие пропусков. При необходимости заменить их на среднее значение признака.\n",
    "3. Добавить столбец brand с информацией о производителе автомобиля (для простоты можно взять первое слово в названии модели)\n",
    "4. Решить, какие признаки Вы хотите сделать категориальными. Конвертировать выбранные категориальные столбцы в тип category. \n",
    "5. Создать датасет А с категориальными признаками в виде категорий. Для этого необходимо создать вектор целевых значений (столбец цен автомобилей) и матрицу признаков с категориальными переменными в виде категорий (получается путем удаления только целевой переменной из матрицы с данными). Дополнительно стоит создать список с названиями и индексами столбцов категориальных переменных (поможет в будущем).\n",
    "6. Создать датасет B без категориальных признаков. Для этого необходимо создать вектор целевых значений (столбец цен автомобилей) и удалить из матрицы признаков столбец с целевыми переменными, а также все категориальные переменные.\n",
    "8. Создать датасет C с категориальными признаками в виде one-hot encoding. Для этого необходимо создать вектор целевых значений (столбец цен автомобилей), удалить из матрицы признаков столбец с целевыми переменными и все категориальными переменные, а затем добавить новые признаки, соответствующие one-hot encoding категориальных переменных (здесь вам поможет функция `pd.get_dummies`).\n",
    "9. Разбить датасеты на тренировочное и тестовое множества, используя `train_test_split(X, y, test_size=0.25, random_state=0)` (зафиксировав random_seed мы получим одинаковое разбиение на обучение/тест для всех трёх выборок)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = {'A' : None, 'B': None, 'C': None}\n",
    "\n",
    "# your awesome code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Итак, кажется, что у нас всё готово для того, чтобы начать искать ответы на волнующие нас вопросы. Начнем со столь любимой нами библиотеки, а именно...\n",
    "\n",
    "## Градиентный бустинг со sklearn\n",
    "\n",
    "Естественно, в sklearn имеется реализация градиентного бустинга, которая хранится в sklearn.ensemble.GradientBoostingRegressor. Преимущественно данным классом пользуются в учебных заданиях, поскольку в реальных задачах предпочтение отдаётся другим библиотекам. Давайте попробуем понять, заслуженно ли градиентный бустинг в sklearn не пользуется популярностью.\n",
    "\n",
    "FYI: в sklearn имеется также реализация GradientBoostingClassifier для задач классификации, но пользоваться им мы сегодня не будем.\n",
    "\n",
    "GradientBoostingRegressor из коробки не умеет работать с категориальными признаками. Мы к этому уже подготовились, закодировав наши признаки.\n",
    "\n",
    "### **Задание 2 (кросс-проверка, 2 балла)**:\n",
    "\n",
    "**Данные**: датасет со стоимостью поддержанных автомобилей    \n",
    "**Метрика**: MAE    \n",
    "**Цели**: В данном задании следует выполнить следующие пункты:    \n",
    "1. Обучить sklearn.ensemble.GradientBoostingRegressor на датасетах B и C, используя параметры n_estimators=1000, max_depth=5, learning_rate=0.1 (наши `test_parameters`). Замерьте время обучения, получите предсказания данных моделей на тестовом множестве.\n",
    "2. Обучить sklearn.ensemble.GradientBoostingRegressor на датасете B (можно и на C, если позволяют вычислительные ресурсы), используя кросс-валидацию на тренировочном множестве и подбирая значения для параметров n_estimators, learning_rate и max_depth. для простоты можете воспользоваться GridSearchCV. При необходимости можно оптимизировать параметры по одному, а не все сразу. Выведите лучшие параметры. Получите предсказания лучшей модели (с лучшими параметрами) на тестовом множестве. Для ускорения процесса не забудьте воспользоваться n_jobs.\n",
    "3. Посчитать MAE для полученных предсказаний на тренировочном и тестовом множествах (можно воспользоваться sklearn.metrics.mean_absolute_error).\n",
    "5. Вывести результаты и время в таблице DataFrame.\n",
    "4. Сделайте выводы. Оцените полезность категориальных переменных и поиска оптимальных параметров. Оцените время, затраченное на обучение. Попробуйте дать оценку получившемуся MAE: оно большое или маленькое?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_skl = pd.DataFrame(columns=['Dataset', 'Parameters', 'Time', 'MAE'])\n",
    "\n",
    "# your cool code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваши выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И так, sklearn предлагает нам привычный и простой способ тренировки моделей. Однако, для градиентного бустинга существует множество эвристик и трюков, помогающих улучшить результаты. И одна из библиотек, реализующая улучшенную версию бустинга, называется xgboost.\n",
    "\n",
    "## Градиентный бустинг с XGBoost\n",
    "\n",
    "XGBoost стала достаточно популярной библиотекой, которая позволяет добиться хороших результатов без особых усилий (во всяком случае, так гласят легенды). И у нас для вас две новости: хорошая и плохая. Хорошая – xgboost, хоть и является сторонней библиотекой, сохраняет интерфейс sklearn и даже прекрасно работает с GridSearchCV. Плохая – она тоже не умеет из коробки работать с категориальными признаками. Ну что же, давайте пощупаем это безобразие. На этот раз нас интересует класс xgboost.XGBRegressor.\n",
    "\n",
    "Update: относительно недавно в xgboost появилась экспериментальная поддержка категориальных переменных, которая еще не добавлена в стабильную версию, поэтому ею мы пользоваться пока не будем.\n",
    "\n",
    "### Задание 3 (кросс-проверка, 2 балла):\n",
    "**Данные**: датасет со стоимостью поддержанных автомобилей  \n",
    "**Метрика**: MAE  \n",
    "**Цели**: В данном задании следует выполнить следующие пункты:  \n",
    "1. Обучить xgboost.XGBRegressor на датасетах B и C, используя параметры n_estimators=1000, max_depth=5, learning_rate=0.1 (наши `test_parameters`). Замерьте время обучения. Получите предсказания данных моделей на тестовом множестве.\n",
    "2. Обучить xgboost.XGBRegressor на датасетах B и C, используя кросс-валидацию на тренировочном множестве и подбирая значения для параметров n_estimators, learning_rate и max_depth (для простоты можете воспользоваться GridSearchCV). При необходимости можно оптимизировать параметры по одному, а не все сразу. Замерьте время перебора, получите предсказания лучшей модели (с лучшими параметрами) на тестовом множестве. В этом случае устанавливать n_jobs у GridSearchCV не рекомендую, поскольку xgboost сам умеет захватывать все доступные ресурсы, и если GridSearchCV начнет их размножать, то последствия будут печальны.\n",
    "3. Посчитать MAE для полученных предсказаний на тренировочном и тестовом множествах (можно воспользоваться sklearn.metrics.mean_absolute_error).\n",
    "1. Выведите результаты и время в таблице DataFrame.\n",
    "4. Сделайте выводы. Оцените полезность категориальных переменных и поиска оптимальных параметров. Оцените время, затраченное на обучение. Сравните результаты со sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_xgb = pd.DataFrame(columns=['Dataset', 'Parameters', 'Time', 'MAE'])\n",
    "\n",
    "# your perfect code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваши выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Таким вот несложным образом нам удалось воспользоваться еще одной библиотекой. Давайте перейдем к третьей библиотеке, которую мы сегодня изучим, и называется она lightgbm.\n",
    "\n",
    "## Градиентный бустинг в lightgbm\n",
    "\n",
    "Про Lightgbm легенды гласят, что она очень быстрая и легкая: что самый большой датасет она без проблем переварит за относительно небольшое время. А еще её разрабатывали не хухры кто, а сами мелкомягкие, так что попробовать её определённо стоит. На этот раз у нас вновь две новости, две хороших и две плохих. Первая хорошая — lightgbm тоже работает с GridSearchCV. Вторая хорошая — lightgbm умеет из коробки работать с категориальными признаками! Плохая — делает она это немного нетривиально (не зря я просил вас запомнить категориальные переменные!). Вторая плохая — да, нам придётся этим пользоваться.\n",
    "\n",
    "Внимание! LightGBM может писать сотню радостных сообщений о том, что он увидел ваши categorical_feature и использует их. При желании можете заглушать эти оповещения, ибо в случае перебора параметров их становится слишком много. (заклинание для заглушения: `warnings.filterwarnings(\"ignore\")`)\n",
    "\n",
    "### Задание 4 (кросс-проверка, 3 балла):\n",
    "**Данные**: датасет со стоимостью поддержанных автомобилей  \n",
    "**Метрика**: MAE  \n",
    "**Цели**: В данном задании следует выполнить следующие пункты:  \n",
    "1. В случае датасета, сохраненном в numpy, lightgbm требует, чтобы категории были закодированы целыми числами от 0 до числа признаков(e.g. ['a', 'b', 'a'] -> [0, 1, 0]). Сделайте это для датасета A. Если вы используете pandas, то для датасета A достаточно установить соответствующие столбцы типа \"категория\", тогда categorical_feature='auto' сам всё подхватит.\n",
    "2. Обучить lightgbm.LGBMRegressor на датасетах A, B и C, используя параметры используя параметры n_estimators=1000, max_depth=5, learning_rate=0.1. В случае датасета A, передайте в функцию fit индексы/имена категориальных признаков. Замерьте время обучения, получите предсказания данных моделей на тестовом множестве.\n",
    "3. Обучить lightgbm.LGBMRegressor на датасетах A, B и C, используя кросс-валидацию на тренировочном множестве и подбирая значения для параметров n_estimators, learning_rate и max_depth (для простоты можете воспользоваться GridSearchCV). Замерьте время, потраченное на поиск оптимальных параметров(вновь не советую использовать n_jobs). Замерьте время перебора, получите предсказания лучшей модели (с лучшими параметрами) на тестовом множестве.\n",
    "4. Посчитать MAE для полученных предсказаний на тренировочном и тестовом множествах (можно воспользоваться sklearn.metrics.mean_absolute_error). Сделайте выводы и полезности использования категориальных переменных и поиска оптимальных параметров.\n",
    "5. Вывести результаты и время в таблице DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_lightgbm = pd.DataFrame(columns=['Dataset', 'Parameters', 'Time', 'MAE'])\n",
    "\n",
    "# your great code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Как вы видите, иногда можно не возиться с OHE, а позволить библиотекам самим это сделать (хотя иногда при этом приходится повозиться с самими данными, чтобы библиотека съела данные).\n",
    "\n",
    "Итак, мы с вами почти стали мастерами градиентного бустинга. Переходим к последней звезде нашего хит-парада.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Градиентный бустинг в catboost\n",
    "\n",
    "Библиотека, созданная в тёмных подвалах яндекса. По легендам эта библиотека умеет работать с категориальными данными, быстрая, эффективная, легко настраивается, из коробки понимает текстовые признаки в задачах классификации и спасла Брюса Уиллиса. Давайте проверим.\n",
    "Вас, наверное, не удивить тем, что эта библиотека работает с GridSearchCV, но им мы пользоваться не будем. В catboost существует своя реализация перебора параметров, и мы попробуем им воспользоваться (ура, разнообразие!). В качестве регрессора нас интересует catboost.CatBoostRegressor.\n",
    "\n",
    "Внимание! Эта библиотека еще более болтлива, чем lightgbm, но это (почти) полностью лечится с помощью verbose. К сожалению, отключением warnings её не сделать молчаливее. А еще эта библиотека может неожиданно создать вам парочку новых папок.\n",
    "\n",
    "### Задание 5 (кросс-проверка, 3 балла):\n",
    "**Данные**: датасет со стоимостью поддержанных автомобилей  \n",
    "**Метрика**: MAE  \n",
    "**Цели**: В данном задании следует выполнить следующие пункты:  \n",
    "1. Обучить catboost.CatBoostRegressor на датасетах A, B и C, используя параметры используя параметры n_estimators=1000, max_depth=5, learning_rate=0.1. В случае датасета A, передайте на вход методу fit/конструктору параметр cat_features, содержащий имена/индексы категориальных переменных. В данном случае переводить категории в целые числа, как мы делали для lightgbm, не нужно. Замерьте время обучения, получите предсказания данных моделей на тестовом множестве.\n",
    "2. Обучить catboost.CatBoostRegressor на датасетах A, B и C, используя метод grid_search (является методом экземпляра класса CatBoostRegressor). Замерьте время, потраченное на поиск оптимальных параметров. Замерьте время перебора, получите предсказания лучшей модели (с лучшими параметрами) на тестовом множестве.\n",
    "3. Посчитать MAE для полученных предсказаний на тренировочном и тестовом множествах (можно воспользоваться sklearn.metrics.mean_absolute_error).\n",
    "4. Сделайте выводы и полезности использования категориальных переменных и поиска оптимальных параметров.\n",
    "5. Вывести результаты и время в таблице DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_catboost = pd.DataFrame(columns=['Dataset', 'Parameters', 'Time', 'MAE'])\n",
    "\n",
    "# your ideal code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваши выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "И так, мы наконец познакомились со всеми библиотеками градиентного бустинга.\n",
    "\n",
    "## Обобщение результатов\n",
    "\n",
    "На текущем этапе у вас должно быть несколько датафреймов результатами по каждой библиотеке. Мы, конечно, сделали некоторые выводы, но пришло время собрать это в красивый отчет.\n",
    "\n",
    "### Задание 6 (кросс-проверка, 3 балла):\n",
    "**Данные**: датасет с ценами поддержанных автомобилей  \n",
    "**Цели**: В данном задании следует выполнить следующие пункты:  \n",
    "1. При помощи одного или нескольких графиков показать результаты различных библиотек: времени работы и качество результатов. Можете воспользоваться любым типом графиков: гистограммы, scatter и т.д. По этим графикам должно быть понятно какая библиотека и насколько быстрее, насколько различается их качество, сравнение оптимизированных и неоптимизированных параметров.\n",
    "2. По графикам сравните библиотеки, производительность и качество работы. Опишите ваши выводы ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Your great pictures and conclusions below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ваши выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Оптимизация параметров с hyperopt\n",
    "\n",
    "И так, мы с вами научились пользоваться библиотеками для градиентного бустинга. И я почти уверен, что знаю вашу самую \"любимую\" часть всех этих заданий: оптимизация параметров. Она достаточно долгая, нудная, да еще и над сетками перебора нужно думать. Значит сейчас, когда вы поняли всю тяжесть этого процесса, мы можем узнать как относительно быстро и безболезненно нащупать оптимальные параметры!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Эмоции выполняющего в этот момент.](https://disk.yandex.ru/i/qwkvBEFrWYoV9A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Нашего спасителя зовут HyperOpt. На первый взгляд hyperopt делает всё то же самое, что и grid search, а именно перебирает параметры. По факту же hyperopt превращает это в задачу оптимизации, используя некоторые эвристики для ускорения сходимости процесса. К тому же, он требует лишь информацию о границе интарвалов, а не сами сетки. В теории это должно помочь нам добиться лучших результатов за более короткое время. Давайте попробуем это сделать.\n",
    "\n",
    "Для данного эксперимента я рекомендую использовать lightgbm, поскольку она быстрее и с ней удобнее играться, но Вы можете воспользоваться любой библиотекой из представленных выше.\n",
    "\n",
    "### Задание 7 (кросс-проверка, 4 балла):\n",
    "**Данные**: датасет со стоимостью поддержанных автомобилей\n",
    "**Метрика**: MAE\n",
    "**Цели**: В данном задании следует выполнить следующие пункты:\n",
    "1. Взять любую библиотеку градиентного бустинга (можете взять самую быструю)\n",
    "2. Составить сетку перебора в hyperopt, включающую параметры n_estimators, max_depth и learning_rate в hyperopt. Вам могут понадобиться такие типы данных, как hp.choise, hp.qloguniform, hp.uniform и hp.quniform (можно также пользоваться np.arange). Также для округления значения типа float до целых чисел (4.0 -> 4) используйте `scope.int`.\n",
    "3. Реализуйте функцию, которая принимает на вход словарь параметров для регрессора, и при помощи cv оценивает его качество на датасете A (можно воспользоваться cross_val_score, а для ускорения поставить cv=3). Не забудьте о том, в каком виде lightgbm принимает категориальные признаки в numpy и что также надо передавать индексы категориальных признаков.\n",
    "4. Создайте объект trials=Trials(), который будет хранить информацию о процессе оптимизации.\n",
    "5. Используя функцию fmin, оптимизируйте Вашу функцию. Установите algo=tpe.suggest, trials=trials и max_evals, по крайней мере, 50. verbose=1 позволит видеть прогресс-бар по типу tqdm.\n",
    "6. Выведите получившиеся параметры. Нарисуйте график, показывающий значение loss в ходе оптимизации. Посчитайте качество на тесте при использовании лучших параметров (возвращаются после использования fmin). Сделайте выводы по результату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "def quality(params):\n",
    "    # your cool function here\n",
    "    return # something\n",
    "\n",
    "grid = {\n",
    "    # your clever grid here\n",
    "}\n",
    "\n",
    "best = fmin(fn=quality,\n",
    "                space=grid,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=trials,\n",
    "               verbose= 1)\n",
    "\n",
    "\n",
    "# your super code for super graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Ваши выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание зрительских симпатий\n",
    "\n",
    "Ну что, детишки, а теперь перейдём к действительно важным вопросам.\n",
    "\n",
    "**Внимание!** Следующее задание сдается в системе cv-gml.ru, задание `Град. бустинг (ML)` Для выполнения этого задания необходимо скачать датасет из задания. Здесь вы можете немного почитать про датасет и, при желании, поэкспериментировать. На cv-gml.ru загружайте уже готовый скрипт с подобранными параметрами для обучаемого регрессора. Релизовать код необходимо в шаблонном файле awards_prediction.py, который вы можете найти в проверяющей системе.\n",
    "\n",
    "В некотором царстве, некотором государстве была развита кинопромышленность. Новые фильмы в этом государстве показывают по интернету, а пользователи после просмотра могут дать фильму некоторую \"награду\". Наша цель - предсказать число наград для фильма.\n",
    "\n",
    "В нашем распоряжении имеются следующие данные:\n",
    "\n",
    "**awards** - количество наград, полученных фильмом от пользователей (целевое значение)  \n",
    "**potions** - количество магических зелий, потраченных на создание спец-эффектов  \n",
    "**genres** - жанры созданного фильма  \n",
    "**questions** - количество вопросов, заданных пользователями на соответствующих форумах об этом фильме до премьеры  \n",
    "**directors** - режиссеры фильма (если неизвестны, то unknown)  \n",
    "**filming_locations** - области, в которых снимался фильм  \n",
    "**runtime** - продолжительность фильма в некоторых единицах, принятых в этом государстве  \n",
    "**critics_liked** - количество критиков из 100, присудивших награды фильму на предварительных закрытых показах  \n",
    "**pre-orders** - количество зрителей, заранее купивших билеты на первый показ  \n",
    "**keywords** - ключевые слова, описывающие содержание фильма\n",
    "**release_year** - год, во котором фильм был показан (конечно, в летоисчислении этого государства)\n",
    "\n",
    "Следующие поля появляются несколько раз с разными значениями i:\n",
    "\n",
    "**actor_i_known_movies** - количество известных фильмов актера i (i от 1 до 3)\n",
    "\n",
    "**actor_i_postogramm** - количество подписчиков в социальной сети \"по сто грамм\" актера i (i от 1 до 3)\n",
    "\n",
    "**actor_i_gender** - пол актера i (i от 1 до 3)\n",
    "\n",
    "**actor_i_age** - возраст актера i (i от 1 до 3)\n",
    "\n",
    "-----\n",
    "**Внимание!** Учтите, что при OHE кодировании признаки на обучении и тестировании должны совпадать! Если вы примените простое .get_dummies() или что-то подобное, то признаки на трейне и тесте получатся разные! Так что вам, вероятно, придётся придумать способ для того, чтобы сохранить их :)  \n",
    "\n",
    "### Задание 8 (ML задание, 20 баллов):\n",
    "**Данные**: датасет с ценами поддержанных автомобилей  \n",
    "**Метрика**: MAE  \n",
    "**Цели**: В данном задании следует выполнить следующие пункты:  \n",
    "1. Взять любую библиотеку градиентного бустинга\n",
    "2. Используя предложенный датасет, обучить регрессор для предсказания awards (предоставляем полную свободу в настройках и выборе методов)\n",
    "3. Загрузить решение и получить качество на закрытой выборке больше порогового значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## your efficient code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Конец\n",
    "\n",
    "Ну что детишки... Можете добавлять еще 4 библиотеки в своё резюме датасаентиста!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
