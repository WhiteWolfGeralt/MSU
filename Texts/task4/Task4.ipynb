{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YbeUQhgyLiJa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import neighbors\n",
        "\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import json\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAbf-GnLYpgS",
        "outputId": "a014dc66-610b-4a0c-e295-ac864965640b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/texts-dev.zip'\n",
        "zipfile.ZipFile(dataset_path, 'r').extractall()\n",
        "\n",
        "session_path = '/content/dev-dataset-task2022-04.json'\n",
        "\n",
        "with open(session_path) as f:\n",
        "  raw_data = json.load(f)"
      ],
      "metadata": {
        "id": "pKZaCTvdZ0xV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = []\n",
        "y_data = []\n",
        "for pair in raw_data:\n",
        "  X_data.append(pair[0])\n",
        "  y_data.append(int(pair[1]))"
      ],
      "metadata": {
        "id": "ECIPn9pFdX4X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(X_data) == len(y_data)"
      ],
      "metadata": {
        "id": "-71Gedkee-Pt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.001, random_state=48151623)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "RFonuBBhfKoM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNirv1Ke6muI",
        "outputId": "0ebdf42e-f68d-4f82-9b5d-1f1af2d91a1a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3219"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kfold_split(num_objects, num_folds):\n",
        "    \"\"\"\n",
        "    Split [0, 1, ..., num_objects - 1] into equal num_folds folds (last fold can be longer) and returns num_folds train-val\n",
        "       pairs of indexes.\n",
        "\n",
        "    Parameters:\n",
        "    num_objects (int): number of objects in train set\n",
        "    num_folds (int): number of folds for cross-validation split\n",
        "\n",
        "    Returns:\n",
        "    list((tuple(np.array, np.array))): list of length num_folds, where i-th element of list contains tuple of 2 numpy arrays,\n",
        "                                       the 1st numpy array contains all indexes without i-th fold while the 2nd one contains\n",
        "                                       i-th fold\n",
        "    \"\"\"\n",
        "    partition = []\n",
        "    size = num_objects // num_folds\n",
        "    for i in range(0, num_folds - 1):\n",
        "        partition.append(list(range(i * size, (i + 1) * size)))\n",
        "    partition.append(list(range(partition[-1][-1] + 1, num_objects)))\n",
        "\n",
        "    ret = []\n",
        "    for part in partition:\n",
        "        ret.append([np.concatenate((np.arange(0, part[0]), np.arange(part[-1] + 1, num_objects))),\n",
        "                    np.arange(part[0], part[-1] + 1)])\n",
        "    return ret"
      ],
      "metadata": {
        "id": "Z93C2Wyxfy4e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_cv_score(x, y, parameters, score_function, folds, knn_class):\n",
        "    \"\"\"\n",
        "    Takes train data, counts cross-validation score over grid of parameters (all possible parameters combinations)\n",
        "\n",
        "    Parameters:\n",
        "    X (2d np.array): train set\n",
        "    y (1d np.array): train labels\n",
        "    parameters (dict): dict with keys from {n_neighbors, metrics, weights, normalizers}, values of type list,\n",
        "                       parameters['normalizers'] contains tuples (normalizer, normalizer_name), see parameters\n",
        "                       example in your jupyter notebook\n",
        "    score_function (callable): function with input (y_predict, y_true) which outputs score metric\n",
        "    folds (list): output of kfold_split\n",
        "    knn_class (obj): class of knn model to fit\n",
        "\n",
        "    Returns:\n",
        "    dict: key - tuple of (normalizer_name, n_neighbors, metric, weight), value - mean score over all folds\n",
        "    \"\"\"\n",
        "    ret = dict()\n",
        "    for i in folds:\n",
        "        for normalizers in parameters['normalizers']:\n",
        "            x_train, x_test = x[i[0]], x[i[1]]\n",
        "            if normalizers[0] is not None:\n",
        "                normalizers[0].fit(x_train)\n",
        "                x_train, x_test = normalizers[0].transform(x_train), normalizers[0].transform(x_test)\n",
        "            for n_neighbors in parameters['n_neighbors']:\n",
        "                for metrics in parameters['metrics']:\n",
        "                    for weights in parameters['weights']:\n",
        "                        print(f\"Training: {normalizers[1]} {weights} {metrics} {n_neighbors}\")\n",
        "                        clf = knn_class(n_neighbors=n_neighbors, weights=weights, metric=metrics)\n",
        "                        clf.fit(x_train, y[i[0]])\n",
        "                        score = score_function(y[i[1]], clf.predict(x_test))\n",
        "                        if (normalizers[1], n_neighbors, metrics, weights) in ret:\n",
        "                            ret[(normalizers[1], n_neighbors, metrics, weights)] += score / len(folds)\n",
        "                        else:\n",
        "                            ret[(normalizers[1], n_neighbors, metrics, weights)] = score / len(folds)\n",
        "    return ret"
      ],
      "metadata": {
        "id": "jtjYMmUpgIO3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bg3KmTAQ8d0",
        "outputId": "ede36a9d-8ef6-4d4e-d52d-ca904d050bcb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "count_vec = CountVectorizer(max_df=0.8, min_df=10)\n",
        "tf_idf = TfidfVectorizer(min_df=3, stop_words=stopwords.words('russian'))"
      ],
      "metadata": {
        "id": "xuvoEGEigNbX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    'n_neighbors': [i for i in range(1, 11)],\n",
        "    'metrics': ['euclidean', 'cosine'],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'normalizers': [(count_vec, 'CountVectorizer'), (tf_idf, 'TfidfVectorizer')]\n",
        "}"
      ],
      "metadata": {
        "id": "8TTUr9aSg8cQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#score_dict = knn_cv_score(X_train, y_train, parameters, accuracy_score, kfold_split(X_train.shape[0], 4), neighbors.KNeighborsClassifier)"
      ],
      "metadata": {
        "id": "Hn3a47AYhZ24"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#max(score_dict, key=score_dict.get)"
      ],
      "metadata": {
        "id": "POHPpUv0i8jV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_data)\n",
        "y_train = np.array(y_data)"
      ],
      "metadata": {
        "id": "gFXfGvDJ61_o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYAbyJ9V91rv",
        "outputId": "866e0504-81f0-4b9e-8846-0f9c358ebac2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3223"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf.fit(X_train)\n",
        "X_train_vec = tf_idf.transform(X_train)"
      ],
      "metadata": {
        "id": "e-NtIqnci_qm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = neighbors.KNeighborsClassifier(n_neighbors = 1, metric ='cosine')\n",
        "clf.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4n41oRTkebn",
        "outputId": "51dc0cb1-fd97-4cee-d61a-3b67f0bdd189"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(metric='cosine', n_neighbors=1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_file = \"KNN_model.pkl\"\n",
        "with open(saved_file, \"wb\") as file:\n",
        "  pickle.dump(clf, file)"
      ],
      "metadata": {
        "id": "rw_ib2UhyAwM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(saved_file, \"rb\") as file:\n",
        "  model = pickle.load(file)"
      ],
      "metadata": {
        "id": "_IZ8ZSbSyu5R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_vectorizer = \"vectorizer.pkl\"\n",
        "with open(saved_vectorizer, \"wb\") as file:\n",
        "  pickle.dump(tf_idf, file)"
      ],
      "metadata": {
        "id": "FPeS7Nxc3v5f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(saved_vectorizer, \"rb\") as file:\n",
        "  vectorizer = pickle.load(file)"
      ],
      "metadata": {
        "id": "rY9ei78E3872"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_vec = vectorizer.transform(X_test)\n",
        "score = accuracy_score(y_test, model.predict(X_test_vec))"
      ],
      "metadata": {
        "id": "r3gZ6wu-zG6F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I9a8pvEzHz9",
        "outputId": "ac0b99f1-766a-484a-a5ed-b02a2bbb507c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}